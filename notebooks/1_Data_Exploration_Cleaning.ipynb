{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49dc881c",
   "metadata": {},
   "source": [
    "# Premier League 2024-25 Data Analysis - Part 1: Exploration & Cleaning\n",
    "\n",
    "This notebook focuses on the initial exploration and cleaning of the Premier League 2024-25 dataset. We'll explore the data structure, handle missing values, and prepare it for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b013cc",
   "metadata": {},
   "source": [
    "# Premier League 2024-25 Data Analysis - Part 1: Exploration & Cleaning\n",
    "\n",
    "This notebook focuses on the initial exploration and cleaning of the Premier League 2024-25 dataset. We'll explore the data structure, handle missing values, and prepare it for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1141aac1",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cc3b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "\n",
    "# Display settings\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab096ba",
   "metadata": {},
   "source": [
    "## 2. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f58a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Premier League dataset\n",
    "file_path = '../data/fbref_PL_2024-25.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check if the file exists and has data\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Number of columns: {len(df.columns)}\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607a122e",
   "metadata": {},
   "source": [
    "## 3. Understanding the Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083f7cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e32de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a56e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Values': missing_values,\n",
    "    'Percentage (%)': missing_percentage\n",
    "})\n",
    "\n",
    "# Display columns with missing values\n",
    "missing_df[missing_df['Missing Values'] > 0].sort_values('Missing Values', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d67eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44698e0",
   "metadata": {},
   "source": [
    "## 4. Explore Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7c97e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Categorical columns: {categorical_columns}\")\n",
    "\n",
    "# Let's explore the distribution of some key categorical variables\n",
    "for col in categorical_columns[:5]:  # Limit to first 5 to avoid overwhelming output\n",
    "    print(f\"\\n{col} - Unique values: {df[col].nunique()}\")\n",
    "    print(df[col].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df7436f",
   "metadata": {},
   "source": [
    "## 5. Explore Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4486fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical columns\n",
    "numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "print(f\"Numerical columns: {len(numerical_columns)}\")\n",
    "\n",
    "# Let's create histograms for some key numerical variables\n",
    "key_numerical = numerical_columns[:5]  # Select first 5 for visualization\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(key_numerical):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    sns.histplot(df[col].dropna(), kde=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f019c417",
   "metadata": {},
   "source": [
    "## 6. Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e850cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original dataframe\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Handle missing values\n",
    "# For numerical columns: fill with median or mean\n",
    "# For categorical columns: fill with mode or 'Unknown'\n",
    "\n",
    "# First, let's examine the columns with missing values to make informed decisions\n",
    "columns_with_missing = missing_df[missing_df['Missing Values'] > 0].index.tolist()\n",
    "print(f\"Columns with missing values: {columns_with_missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f3842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of cleaning logic for our dataset\n",
    "\n",
    "# 1. Convert data types\n",
    "# Convert numerical columns that might be stored as strings\n",
    "numeric_cols = ['Age', 'Born', 'MP', 'Starts', 'Min', '90s', 'Gls', 'Ast', 'G+A', \n",
    "                'G-PK', 'PK', 'PKatt', 'CrdY', 'CrdR', 'xG', 'npxG', 'xAG']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "\n",
    "# 2. Handle missing values\n",
    "# For numerical columns: fill with median\n",
    "for col in df_clean.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    if df_clean[col].isnull().sum() > 0:\n",
    "        median_val = df_clean[col].median()\n",
    "        df_clean[col] = df_clean[col].fillna(median_val)\n",
    "        print(f\"Filled {col} missing values with median: {median_val}\")\n",
    "\n",
    "# For categorical columns: fill with 'Unknown'\n",
    "for col in df_clean.select_dtypes(include=['object']).columns:\n",
    "    if df_clean[col].isnull().sum() > 0:\n",
    "        df_clean[col] = df_clean[col].fillna('Unknown')\n",
    "        print(f\"Filled {col} missing values with 'Unknown'\")\n",
    "\n",
    "# 3. Handle duplicates\n",
    "dupe_count = df_clean.duplicated().sum()\n",
    "if dupe_count > 0:\n",
    "    df_clean = df_clean.drop_duplicates()\n",
    "    print(f\"Removed {dupe_count} duplicate rows\")\n",
    "else:\n",
    "    print(\"No duplicates found\")\n",
    "\n",
    "# 4. Clean up text data\n",
    "# Example: Standardize team names if needed\n",
    "if 'Squad' in df_clean.columns:\n",
    "    # Print unique values to check if standardization is needed\n",
    "    print(\"\\nUnique team names:\")\n",
    "    print(df_clean['Squad'].unique())\n",
    "\n",
    "# 5. Identify and handle outliers\n",
    "# Example: Check for outliers in the Age column\n",
    "if 'Age' in df_clean.columns:\n",
    "    q1 = df_clean['Age'].quantile(0.25)\n",
    "    q3 = df_clean['Age'].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - (1.5 * iqr)\n",
    "    upper_bound = q3 + (1.5 * iqr)\n",
    "    \n",
    "    outliers = df_clean[(df_clean['Age'] < lower_bound) | (df_clean['Age'] > upper_bound)]\n",
    "    print(f\"\\nNumber of age outliers: {len(outliers)}\")\n",
    "    if len(outliers) > 0:\n",
    "        print(\"Age outliers:\")\n",
    "        print(outliers[['Player', 'Age', 'Squad']].head())\n",
    "\n",
    "# Print the shape after cleaning\n",
    "print(f\"\\nDataset shape after cleaning: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3724fa54",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8358022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new features that might be useful for analysis\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Create goals per 90 minutes\n",
    "df_clean['goals_per_90'] = df_clean['Gls'] / df_clean['90s']\n",
    "\n",
    "# Create assists per 90 minutes\n",
    "df_clean['assists_per_90'] = df_clean['Ast'] / df_clean['90s']\n",
    "\n",
    "# Create goal contributions (G+A) per 90 minutes\n",
    "df_clean['goal_contributions_per_90'] = df_clean['G+A'] / df_clean['90s']\n",
    "\n",
    "# Calculate minutes per goal\n",
    "df_clean['minutes_per_goal'] = df_clean['Min'] / df_clean['Gls'].replace(0, np.nan)\n",
    "\n",
    "# Calculate goal conversion rate (goals divided by expected goals)\n",
    "df_clean['goal_conversion'] = df_clean['Gls'] / df_clean['xG']\n",
    "\n",
    "# Calculate assist conversion rate (assists divided by expected assisted goals)\n",
    "df_clean['assist_conversion'] = df_clean['Ast'] / df_clean['xAG']\n",
    "\n",
    "# Calculate minutes played percentage (based on total possible minutes)\n",
    "# Assuming a full season has 38 games * 90 minutes = 3420 minutes\n",
    "df_clean['minutes_percentage'] = (df_clean['Min'] / 3420) * 100\n",
    "\n",
    "# Calculate starts percentage\n",
    "df_clean['starts_percentage'] = (df_clean['Starts'] / df_clean['MP']) * 100\n",
    "\n",
    "# Handle infinity and NaN values from divisions by zero\n",
    "df_clean.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Display the new features\n",
    "print(\"New features created:\")\n",
    "new_features = ['goals_per_90', 'assists_per_90', 'goal_contributions_per_90', \n",
    "               'minutes_per_goal', 'goal_conversion', 'assist_conversion',\n",
    "               'minutes_percentage', 'starts_percentage']\n",
    "df_clean[new_features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509b1594",
   "metadata": {},
   "source": [
    "## 8. Save Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc7bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned dataset\n",
    "df_clean.to_csv('../data/pl_2024_25_cleaned.csv', index=False)\n",
    "print(\"Cleaned dataset saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9a1fab",
   "metadata": {},
   "source": [
    "## 9. Preliminary Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20b7f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some initial visualizations to understand the data better\n",
    "# These will be expanded in the next notebook focused on visualization\n",
    "\n",
    "# Example visualization code (to be modified based on actual data):\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.heatmap(df_clean[numerical_columns[:10]].corr(), annot=True, cmap='coolwarm')\n",
    "# plt.title('Correlation Matrix of Key Numerical Features')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a78ffe",
   "metadata": {},
   "source": [
    "## 10. Next Steps\n",
    "\n",
    "In the next notebook, we'll:\n",
    "1. Perform in-depth statistical analysis\n",
    "2. Create comprehensive visualizations\n",
    "3. Identify patterns and trends in the data\n",
    "4. Prepare for predictive modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd96120",
   "metadata": {},
   "source": [
    "## 13. Data Dictionary\n",
    "\n",
    "Based on our exploration, here's an explanation of the key columns in our dataset:\n",
    "\n",
    "- **Rk**: Rank or index number\n",
    "- **Player**: Player's name\n",
    "- **Nation**: Player's nationality\n",
    "- **Pos**: Player's position (DF: Defender, MF: Midfielder, FW: Forward)\n",
    "- **Squad**: The team/club the player belongs to\n",
    "- **Age**: Player's age\n",
    "- **Born**: Year of birth\n",
    "- **MP**: Matches played\n",
    "- **Starts**: Number of matches started\n",
    "- **Min**: Minutes played\n",
    "- **90s**: Number of 90-minute periods played (Minutes played / 90)\n",
    "- **Gls**: Goals scored\n",
    "- **Ast**: Assists\n",
    "- **G+A**: Goals + Assists\n",
    "- **G-PK**: Non-penalty goals\n",
    "- **PK**: Penalty kicks scored\n",
    "- **PKatt**: Penalty kicks attempted\n",
    "- **CrdY**: Yellow cards\n",
    "- **CrdR**: Red cards\n",
    "- **xG**: Expected goals\n",
    "- **npxG**: Non-penalty expected goals\n",
    "- **xAG**: Expected assisted goals\n",
    "- **PrgC**: Progressive carries\n",
    "- **PrgP**: Progressive passes\n",
    "- **PrgR**: Progressive passes received\n",
    "\n",
    "The dataset appears to contain player-level statistics from the English Premier League 2024-25 season."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
